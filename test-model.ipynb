{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import torch\n",
    "import unicodedata\n",
    "from transformers import XLMRobertaForSequenceClassification, XLMRobertaTokenizer\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained(\"./Model\")\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained(\"./Model\")\n",
    "\n",
    "with open(\"label-mapping.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    intent_mapping = json.load(f)\n",
    "\n",
    "with open(\"combine-data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    response_list = json.load(f)\n",
    "\n",
    "embedder = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "def clean_text(text):\n",
    "    text = unicodedata.normalize(\"NFKC\", text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "def predict_intent(question):\n",
    "    inputs = tokenizer(question, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    predicted_label = torch.argmax(outputs.logits, dim=1).item()\n",
    "    intent = intent_mapping.get(str(predicted_label), \"UnknownIntent\")\n",
    "    print(f\"Predicted Intent: {intent}\")\n",
    "    return intent\n",
    "\n",
    "def fallback_intent(question):\n",
    "    cleaned = clean_text(question)\n",
    "    for item in response_list:\n",
    "        if clean_text(item[\"keyword\"]) in cleaned:\n",
    "            print(f\"Fallback Intent Found: {item['intent']}\")\n",
    "            return item[\"intent\"]\n",
    "    return \"UnknownIntent\"\n",
    "\n",
    "def get_response(intent, question):\n",
    "    cleaned_question = clean_text(question)\n",
    "    filtered_responses = [item for item in response_list if item[\"intent\"].lower() == intent.lower()]\n",
    "\n",
    "    print(f\"Looking for responses with intent: {intent}\")\n",
    "    \n",
    "    if not filtered_responses:\n",
    "        print(f\"No responses found for intent: {intent}\")\n",
    "        return \"Sorry, I cannot answer that.\"\n",
    "\n",
    "    print(f\"Found {len(filtered_responses)} response(s) for intent '{intent}'\")\n",
    "\n",
    "    filtered_keywords = [clean_text(item[\"keyword\"]) for item in filtered_responses]\n",
    "    filtered_embeddings = embedder.encode(filtered_keywords, convert_to_tensor=True)\n",
    "    question_embedding = embedder.encode(cleaned_question, convert_to_tensor=True)\n",
    "\n",
    "    similarities = util.pytorch_cos_sim(question_embedding, filtered_embeddings).squeeze()\n",
    "    best_idx = int(torch.argmax(similarities))\n",
    "    best_score = float(similarities[best_idx])\n",
    "    best_item = filtered_responses[best_idx]\n",
    "\n",
    "    print(f\"Best Match: '{best_item['keyword']}' | Score: {best_score:.2f}\")\n",
    "\n",
    "    # Fallback: if similarity is too low, try keyword substring match\n",
    "    if best_score < 0.3:\n",
    "        print(\"Low semantic score, trying direct keyword match...\")\n",
    "        for item in filtered_responses:\n",
    "            if clean_text(item[\"keyword\"]) in cleaned_question:\n",
    "                print(f\"Found match by keyword: {item['keyword']}\")\n",
    "                return format_answer(item[\"answer\"])\n",
    "        return \"Sorry, I don't have an answer for that.\"\n",
    "\n",
    "    return format_answer(best_item[\"answer\"])\n",
    "\n",
    "def format_answer(answer):\n",
    "    if isinstance(answer, dict):\n",
    "        return json.dumps(answer, indent=2, ensure_ascii=False)\n",
    "    return str(answer)\n",
    "\n",
    "def chatbot_response(user_question):\n",
    "    intent = predict_intent(user_question)\n",
    "\n",
    "    # If model fails, try fallback\n",
    "    if intent == \"UnknownIntent\":\n",
    "        intent = fallback_intent(user_question)\n",
    "\n",
    "    return get_response(intent, user_question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Intent: Wing-Mastercard\n",
      "Looking for responses with intent: Wing-Mastercard\n",
      "Found 13 response(s) for intent 'Wing-Mastercard'\n",
      "Best Match: 'feature benefit wing mastercard' | Score: 0.71\n",
      "Bot: {\n",
      "  \"Wing Mastercard off many features and benefits including More convenient and secure\": [\n",
      "    \"Carry less cash, make secure payments, receive transaction notifications, and enjoy EMV 3D Secure and contactless chip technology protection\"\n",
      "  ],\n",
      "  \"Access ATMs and merchants worldwide\": [\n",
      "    \"Access Nation/World-wide ATM cash withdrawal and merchant outlets that Mastercard is accepted\"\n",
      "  ],\n",
      "  \"Better control and manage transactions\": [\n",
      "    \"Manage daily cash withdrawal/purchase limit, change PIN, Change Link account, and View and download up to 180 days of transaction history in the Wing Bank App\"\n",
      "  ],\n",
      "  \"Enjoy promotions\": [\n",
      "    \"Take advantage of exclusive promotions from Wing Bank and Visa merchant outlets\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "question = \"mastercard benefit\"\n",
    "print(\"Bot:\", chatbot_response(question))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
